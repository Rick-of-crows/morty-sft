[
    {
        "instruction": "多进程最佳实践\\ntorch.multiprocessing是Pythonmultiprocessing的替代品。它支持完全相同的操作，但扩展了它以便通过multiprocessing.Queue发送的所有张量将其数据移动到共享内存中，并且只会向其他进程发送一个句柄。\\nNote\\n当Variable发送到另一个进程时，Variable.data和Variable.grad.data都将被共享。\\n这允许实现各种训练方法，如Hogwild，A3C或需要异步操作的任何其他方法。\\n共享CUDA张量\\n仅在Python 3中使用spawn或forkserver启动方法才支持在进程之间共享CUDA张量。Python 2中的multiprocessing只能使用fork创建子进程，并且不被CUDA运行时所支持。\\nWarning\\nCUDA API要求导出到其他进程的分配，只要它们被使用就要一直保持有效。您应该小心，确保您共享的CUDA张量只要有必要就不要超出范围。这不是共享模型参数的问题，但传递其他类型的数据应该小心。注意，此限制不适用于共享CPU内存。\\n参考：使用 nn.DataParallel 替代 multiprocessing\\n最佳实践和提示\\n避免和抵制死锁\\n当一个新进程被产生时，有很多事情可能会出错，最常见的死锁原因是后台线程。如果有任何线程持有锁或导入模块，并且fork被调用，则子进程很可能处于损坏的状态，并以不同的方式死锁或失败。注意，即使您没有，Python内置的库也可能会这样做 —— 不需要看得比multiprocessing更远。multiprocessing.Queue实际上是一个非常复杂的类，它产生用于序列化，发送和接收对象的多个线程，它们也可能引起上述问题。如果您发现自己处于这种情况，请尝试使用multiprocessing.queues.SimpleQueue，这不会使用任何其他线程。\\n我们正在竭尽全力把它设计得更简单，并确保这些死锁不会发生，但有些事情无法控制。如果有任何问题您无法一时无法解决，请尝试在论坛上提出，我们将看看是否可以解决问题。\\n重用经过队列的缓冲区\\n记住每次将Tensor放入multiprocessing.Queue时，必须将其移动到共享内存中。如果它已经被共享，它是一个无效的操作，否则会产生一个额外的内存副本，这会减缓整个进程。即使你有一个进程池来发送数据到一个进程，使它返回缓冲区 —— 这几乎是免费的，并且允许你在发送下一个batch时避免产生副本。\\n异步多进程训练（例如Hogwild）\\n使用torch.multiprocessing，可以异步地训练模型，参数可以一直共享，也可以定期同步。在第一种情况下，我们建议发送整个模型对象，而在后者中，我们建议只发送state_dict()。\\n我们建议使用multiprocessing.Queue来在进程之间传递各种PyTorch对象。例如， 当使用fork启动方法时，可能会继承共享内存中的张量和存储器，但这是非常容易出错的，应谨慎使用，而且只能由高级用户使用。队列虽然有时是一个较不优雅的解决方案，但基本上能在所有情况下正常工作。\\nWarning 你应该注意有关全局语句，它们没有被if __name__ == '__main__'保护。如果使用与fork不同的启动方法，则它们将在所有子进程中执行。\\nHogwild\\n在examples repository中可以找到具体的Hogwild实现，可以展示代码的整体结构。下面也有一个小例子：\n```\nimport torch.multiprocessing as mp\nfrom model import MyModel\n\ndef train(model):\n    # Construct data_loader, optimizer, etc.\n    for data, labels in data_loader:\n        optimizer.zero_grad()\n        loss_fn(model(data), labels).backward()\n        optimizer.step()  # This will update the shared parameters\n\nif __name__ == '__main__':\n    num_processes = 4\n    model = MyModel()\n    # NOTE: this is required for the ``fork`` method to work\n    model.share_memory()\n    processes = []\n    for rank in range(num_processes):\n        p = mp.Process(target=train, args=(model,))\n        p.start()\n        processes.append(p)\n    for p in processes:\n      p.join()\n\n```\n基于上面的文章请回答：如何避免和抵制死锁？",
        "lang": "CN",
        "output": "避免和抵制死锁的方法主要包括以下几点：\n1. **注意后台线程**：当一个新进程被产生时，最常见的死锁原因是后台线程。如果有任何线程持有锁或导入模块，并且fork被调用，则子进程很可能处于损坏的状态，并以不同的方式死锁或失败。因此，需要注意管理和控制后台线程的行为。\n2. **使用`multiprocessing.queues.SimpleQueue`**：如果发现自己处于死锁的情况，可以尝试使用`multiprocessing.queues.SimpleQueue`，这不会使用任何其他线程，从而降低死锁的可能性。\n3. **避免全局语句**：你应该注意有关全局语句，它们没有被`if __name__ == '__main__'`保护。如果使用与fork不同的启动方法，则它们将在所有子进程中执行，可能会导致死锁。\n4. **寻求社区帮助**：如果有任何问题你无法一时无法解决，请尝试在论坛上提出，可能会有其他人遇到过类似的问题并找到了解决方案。\n以上就是避免和抵制死锁的一些方法，希望对你有所帮助。",
        "question_num": 35,
        "source": "human",
        "type": "mrc_software"
    },
    {
        "instruction": "阅读下面文章并回答问题：\n\n云盘文件（夹） 相关功能讲解\n2.4.1、 新建文件（夹）\n点击新建按钮，会弹出新建文件夹和模板文件（Word、 PPT、 Excel、文本文档）。选择点击需要新建的文件夹或模板，文件或文件夹将会出现在文件列表中，而且建立成功后，默认是重命名选中状态，可以将文件夹或模板文件改为你需要的名称。\n2.4.2、 文件（夹） 的上传与下载\n2.4.4.1、 文件(夹)上传\ni. 点击上传按钮，选择需要上传的文件或文件夹，点击确定。\nii. 将文件拖动到文件列表中。 注：网页端需要将文件拖动到上传窗口里。\n2.4.4.2、 文件(夹)下载\ni. 选中文件直接双击文件，文件直接下载并打开。\nii. 选中文件(夹)点击下载按钮，选中本地下载位置，点击确定下载。\niii. 在 PC 客户端中，选中文件鼠标拖动到本地目录。\n2.4.4.3、 文件打开与编辑\n直接双击文件，文件将会被下载，并且用本地应用打开。Office 文件默认双击打开为只读模式，可以在本地 office 插件中点击编辑，或直接在文件 操作菜单中点击编辑按钮，进入编辑模式。Office 文件如果以编辑模式打开，文件将会自动锁定，进入独占编辑模式。当此文件关闭 上传后，文件将会自动解锁。如果设置了同步或备份功能，文件双击打开为编辑模式，且不会锁定。\n注：\n1. 本地打开需要本地有能够打开此文件的工具。\n2. office 插件和自动解锁功能暂时只支持 windows 版本的 Microsoftoffice，其它软件只能点击编辑按钮进入编辑模式，而且需要手动解锁。\n3. 可以在软件设置中设置是否使用双击只读打开功能和自动锁定文件的格式。（详情请查看软件设置）\n\n问题：请问云盘如何进行文件复制和剪切？",
        "lang": "CN",
        "output": "对不起，根据您提供的文章内容，文章并未提供关于云盘如何进行文件复制和剪切的具体操作步骤。如果需要了解这部分内容，可能需要查阅更多的相关资料或者直接在云盘的帮助文档或者用户手册中查找。",
        "question_num": 35,
        "source": "human",
        "type": "mrc_software"
    },
    {
        "instruction": "各 linux 系统安装根证书教程\n按系统分类执行相应命令安装即可。 注意带有图形界面的系统， 如果想使用浏览器访问使用自签名证书的网站， 需要将根证书导入浏览器。\n centos7 和 redhat7 系统\n cp rootCA.crt /etc/pki/ca-trust/source/anchors/ \n update-ca-trust extract \nUbuntu 系统\n cp rootCA.crt /usr/local/share/ca-certificates \n update-ca-certificates \n OpenSUSE 系统 \n cp rootCA.crt /etc/pki/trust/anchors \n update-ca-certificates \n Debian 系统 \n mkdir /usr/local/share/ca-certificates/extra \n cp rootCA.crt /usr/local/share/ca-certificates/extra/ \n update-ca-certificates \n 验证证书是否安装成功 \n 安装 curl 命令 \n 运行命令验证 \n curl https://service-desk.cloudwalk.work:10443/ 请根据上面的文章内容回答问题：Debian 系统如何安装证书？",
        "lang": "CN",
        "output": "在 Debian 系统中，根证书的安装过程如下：\n1. 首先，创建一个新的目录来存放证书: \nmkdir /usr/local/share/ca-certificates/extra\n2. 然后，将根证书复制到新创建的目录中：\ncp rootCA.crt /usr/local/share/ca-certificates/extra/ \n3. 最后，更新系统的证书信息：\nupdate-ca-certificates\n完成以上步骤后，证书应该已经成功安装到 Debian 系统中了。",
        "question_num": 35,
        "source": "human",
        "type": "mrc_software"
    },
    {
        "instruction": "阅读文章内容并回答问题：\n\n2.4 安装授权\n2.4.1 在线授权\n在线授权， 需在联网条件下操作！\n（1） 进入/root/UkeyLinux 目录下， 执行如下命令安装授权赋予授权安装文件读写权限： chmod 777 activator执行授权安装文件： ./activator\n（2） 执行以上命令后， 出现如下输出：Please input the haspkey Activation code:\n（3） 输入 1， 回车， 提示输入产品密钥；\n（4） 输入产品密钥， 回车， 如下所示：Install successfully. 即安装授权成功！\n2.4.2 离线授权\n如果需要授权的 linux 设备是离线状态， 可以通过离线授权的方式对该设备进行授权， 操作步骤如下：\n（1） 采集设备机器指纹（fingerprint.c2v）， 参考 2.4.2 章节内容；\n（2） 拷贝该机器指纹到可以联网的 windows 设备上， 使用 windows 授权工具， 通过产品密钥和机器指纹生成授权文件（fingerprint.V2C）；\n（3） 拷贝生成的授权文件至 Linux 系统/root/UkeyLinux 目录下；\n（4） 在 Linux 系 统 上 ， 进 入 /root/UkeyLinux 目 录 下 ， 执 行 命令： ./activator\n（5） 输入 4， 回车， 提示输入授权文件；\n（6） 输入授权文件名称 fingerprint.V2C， 提示安装成功， 则离线授权成功！\n\n问题：在进行在线授权操作时，以下哪个步骤是正确的？\nA. 进入/root/UkeyLinux 目录下，执行命令 chmod 777 activator\nB. 输入 4，回车，提示输入产品密钥\nC. 输入授权文件名称 fingerprint.V2C，提示安装成功\nD. 拷贝生成的授权文件至 Linux 系统/root/UkeyWindows 目录下",
        "lang": "CN",
        "output": "A. 进入/root/UkeyLinux 目录下，执行命令 chmod 777 activator",
        "question_num": 35,
        "source": "human",
        "type": "mrc_software"
    },
    {
        "instruction": "根据下面的文章回答问题：\n\nBF16Optimizer\n用 FP16 训练巨型 LLM 模型是一个禁忌。\n我们已经通过花费几个月的时间 训练 104B 模型 自证了这一点，你可以从 Tensorboard 发现，彻头彻尾地失败了。在与不断发散的 lm-loss 作斗争的过程中，我们学到了很多:104B-fail\n我们也从 Megatron-LM 和 DeepSpeed 团队那里得到了相同的建议，在他们训得 530B 模型 后。最近发布的 OPT-175B 也报告说他们在 FP16 上训练得非常艰难。\n所以早在一月份，我们就知道我们要在支持 BF16 格式的 A100 上进行训练。Olatunji Ruwase 开发了一个用来训练 BLOOM 的 BF16Optimizer。\n如果您不熟悉这种数据格式，请查看它的 位布局。BF16 格式的关键是它的指数位数与 FP32 相同，因此不会溢出，但 FP16 经常溢出！FP16 的最大数值范围为 64k，您只能进行较小数的乘法。例如你可以做 250*250=62500，但如果你尝试 255*255=65025，你就会溢出，这是导致训练出现问题的主要原因。这意味着你的权重必须保持很小。一种称为损失缩放 (loss scaling) 的技术有助于缓解这个问题，但是当模型变得非常大时，FP16 较小的数值范围仍然是一个问题。\nBF16 没有这个问题，你可以很容易地做 10_000*10_000=100_000_000, 完全没问题。\n当然，由于 BF16 和 FP16 的大小相同，均为 2 个字节，因此，没有免费的午餐，当使用 BF16 时，代价就是它的精度非常差。然而，你应该还记得我们在训练时采用的随机梯度下降法及其变体，该方法有点像蹒跚而行，如果你这步没有找到完美的方向其实没关系，你会在接下来的步骤中纠正自己。\n无论使用 BF16 还是 FP16，都有一个权重副本始终在 FP32 中 —— 这是由优化器更新的内容。因此 16 位格式仅用于计算，优化器以全精度更新 FP32 权重，然后将它们转换为 16 位格式以用于下一次迭代。\n所有 PyTorch 组件都已更新，以确保它们在 FP32 中执行任何累加，因此不会发生精度损失。\n一个关键问题是梯度累积，它是流水线并行的主要特征之一，因为每个 micro batch 处理的梯度都会累积。在 FP32 中实现梯度累积以保证训练的精确性至关重要，这正是 BF16Optimizer 所做的。\n\n问题：在训练巨型 LLM 模型时，使用 BF16 格式可以避免 FP16 经常出现的溢出问题吗？",
        "lang": "CN",
        "output": "是的，在训练巨型 LLM 模型时，使用 BF16 格式可以避免 FP16 经常出现的溢出问题。BF16 格式的关键是它的指数位数与 FP32 相同，因此不会溢出，但 FP16 经常溢出。例如，FP16 的最大数值范围为 64k，只能进行较小数的乘法，而 BF16 没有这个问题。",
        "question_num": 35,
        "source": "human",
        "type": "mrc_software"
    },
    {
        "instruction": "阅读文章并回答问题：\n\nPromptSource\nPromptSource is a toolkit for creating, sharing and using natural language prompts.\nRecent work has shown that large language models exhibit the ability to perform reasonable zero-shot generalization to new tasks. For instance, GPT-3 demonstrated that large language models have strong zero- and few-shot abilities. FLAN and T0 then demonstrated that pre-trained language models fine-tuned in a massively multitask fashion yield even stronger zero-shot performance. A common denominator in these works is the use of prompts which have gathered of interest among NLP researchers and engineers. This emphasizes the need for new tools to create, share and use natural language prompts.\nPrompts are functions that map an example from a dataset to a natural language input and target output PromptSource contains a growing collection of prompts (which we call P3: Public Pool of Prompts). As of January 20, 2022, there are ~2'000 English prompts for 170+ English datasets in P3.\nPromptSource provides the tools to create, and share natural language prompts (see How to create prompts, and then use the thousands of existing and newly created prompts through a simple API (see How to use prompts). Prompts are saved in standalone structured files and are written in a simple templating language called Jinja. An example of prompt availabe in PromptSource for SNLI is:\n{{premise}}\nQuestion: Does this imply that \"{{hypothesis}}\"? Yes, no, or maybe? ||| {{answer_choices[label]}}\nYou can browse through existing prompts on the hosted version of PromptSource.\nSetup\nIf you do not intend to modify prompts, you can simply run:\npip install promptsource\nOtherwise, you need to install the repo locally:\n1. Download the repo\n2. Navigate to the root directory of the repo\n3. Run pip install -e . to install the promptsource module\nNote: for stability reasons, you will currently need a Python 3.7 environment to run the last step. However, if you only intend to use the prompts, and not create new prompts through the interface, you can remove this constraint in the setup.py and install the package locally.\n\n问题：如何离线安装PromptSource？",
        "lang": "CN",
        "output": "离线安装PromptSource的步骤如下：\n1. 下载repo\n2. 导航到repo的根目录\n3. 运行`pip install -e .`来安装promptsource模块\n注意：出于稳定性的考虑，你当前需要一个Python 3.7环境来运行最后一步。然而，如果你只打算使用prompts，而不通过接口创建新的prompts，你可以在setup.py中移除这个约束并在本地安装包。",
        "question_num": 36,
        "source": "human",
        "type": "mrc_software"
    },
    {
        "instruction": "阅读以下内容并回答问题：\n\n# Docker\n\nDocker 使用容器创建虚拟环境，以便将 TensorFlow 安装结果与系统的其余部分隔离开来。TensorFlow 程序在此虚拟环境中运行，该环境能够与其主机共享资源（访问目录、使用 GPU、连接到互联网等）。我们会针对每个版本测试 TensorFlow Docker 映像。\n\nDocker 是在 Linux 上启用 TensorFlow GPU 支持的最简单方法，因为只需在主机上安装 NVIDIA® GPU 驱动程序，而不必安装 NVIDIA® CUDA® 工具包。\n\n## TensorFlow Docker 要求\n- 在本地主机上安装 Docker。\n- 如需在 Linux 上启用 GPU 支持，请安装 NVIDIA Docker 支持。\n- 请通过 `docker -v` 检查 Docker 版本。对于 19.03 之前的版本，您需要使用 `nvidia-docker2` 和 `--runtime=nvidia` 标记；对于 19.03 及之后的版本，您将需要使用 `nvidia-container-toolkit` 软件包和 `--gpus all` 标记。这两个选项都记录在上面链接的网页上。\n- 注意：如需在没有 sudo 的情况下运行 docker 命令，请创建 docker 组并添加您的用户。有关详情，请参阅针对 Linux 的安装后步骤。\n\n## 下载 TensorFlow Docker 映像\n官方 TensorFlow Docker 映像位于 tensorflow/tensorflow Docker Hub 代码库中。映像版本按照以下格式进行标记：\n\n标记 | 说明\n--- | ---\nlatest | TensorFlow CPU 二进制映像的最新版本。（默认版本）\nnightly | TensorFlow 映像的每夜版。（不稳定）\nversion | 指定 TensorFlow 二进制映像的版本，例如：2.1.0\ndevel | TensorFlow master 开发环境的每夜版。包含 TensorFlow 源代码。\ncustom-op | 用于开发 TF 自定义操作的特殊实验性映像。详见此处。\n\n每个基本标记都有会添加或更改功能的变体：\n\n标记变体 | 说明\n--- | ---\ntag-gpu | 支持 GPU 的指定标记版本。（详见下文）\ntag-jupyter | 针对 Jupyter 的指定标记版本（包含 TensorFlow 教程笔记本）\n\n您可以一次使用多个变体。例如，以下命令会将 TensorFlow 版本映像下载到计算机上：\n\n```bash\ndocker pull tensorflow/tensorflow                     # latest stable release\ndocker pull tensorflow/tensorflow:devel-gpu           # nightly dev release w/ GPU support\ndocker pull tensorflow/tensorflow:latest-gpu-jupyter  # latest release w/ GPU support and Jupyter\n```\n\n## 启动 TensorFlow Docker 容器\n要启动配置 TensorFlow 的容器，请使用以下命令格式：\n\n```bash\ndocker run [-it] [--rm] [-p hostPort:containerPort] tensorflow/tensorflow[:tag] [command]\n```\n\n有关详情，请参阅 docker 运行参考文档。\n\n### 使用仅支持 CPU 的映像的示例\n我们使用带 latest 标记的映像验证 TensorFlow 安装效果。Docker 会在首次运行时下载新的 TensorFlow 映像：\n\n```bash\ndocker run -it --rm tensorflow/tensorflow \\\n   python -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\n```\n\n成功：TensorFlow 现已安装完毕。请查看教程开始使用。\n\n问题：如何在 Docker 中启动配置 TensorFlow 的容器？",
        "lang": "CN",
        "output": "要启动配置 TensorFlow 的容器，可以使用以下命令格式：`docker run [-it] [--rm] [-p hostPort:containerPort] tensorflow/tensorflow[:tag] [command]`。",
        "question_num": 36,
        "source": "human",
        "type": "mrc_software"
    },
    {
        "instruction": "一、统一接口说明\n\n1. 获取镜像\n\n使用以下命令获取镜像：\n\n```\ndocker pull harbor.cloudwalk.work/research-dev-public/nlpflow:20200803\n```\n\n2. 内部端口号\n\ndocker内部端口号默认为9003，可以在`nlpflow/start.sh`文件中修改，如下：\n\n```\n--port \"9003\"\n```\n\n3. 启动docker并映射端口\n\n默认参数\n\n使用以下命令启动docker并映射端口：\n\n```\ndocker run -p 宿主机端口:9003 -it -v 服务器nlpflow文件夹所在路径:/nlpflow harbor.cloudwalk.work/research-dev-public/nlpflow:20200803 /bin/bash ./nlpflow/start.sh\n```\n\n如果在运行`docker run`时出现cuda错误，可以尝试使用`nvidia-docker run`。\n\n接口对应的Router\n\n| 引擎 | 功能 | Router |\n| --- | --- | --- |\n| 场景切分 | 切分经理话术和客户的话术 | api_text_split |\n| 承诺收益识别 | 判断客户经理的话术中是否承诺了收益 | api_sensitive |\n\n二、配置文件\n\n1. 启动shell文件说明\n\n使用以下命令启动shell文件：\n\n```\n./nluservice --config \"../resources/config.json\" --port \"9003\" --logLevel=error\n```\n\n参数说明：\n\n| 参数 | 说明 |\n| --- | --- |\n| --config \"../resources/config.json\" | 指定模型所用的配置文件 |\n| --port \"9003\" | 指定docker内部端口号 |\n| --logLevel=error | 指定logging的等级 |\n\n2. 模型配置文件说明\n\n参数说明：\n\n| 参数 | 说明 |\n| --- | --- |\n| instNum | 实例数量，如:2表示将为该模型生成两个实例 |\n| device | 每个实例的设备，设备之间用\"-\"连接，如：cuda:0-cpu表示第一个实例放在cuda:0上，第二个实例放在内存上。设备数量应与设置的实例数量保持一致 |\n| useDynamicBatching | 是否使用动态batch。字符串\"True\"表示使用动态batch，其他字符串表示不使用动态batch |\n| baseBatchSize | 当使用动态batch时，打包后batchSize的底线。仅在useDynamicBatching为\"True\"时有效 |\n| api | 指定某个模型使用的router名称 |请根据上面的文章回答相关问题：如何修改Docker内部的默认端口号？",
        "lang": "CN",
        "output": "Docker内部的默认端口号可以在`nlpflow/start.sh`文件中修改，具体操作如下：在文件中找到`--port \"9003\"`这一部分，将其中的\"9003\"替换为你想要设置的新端口号。",
        "question_num": 36,
        "source": "human",
        "type": "mrc_software"
    },
    {
        "instruction": "Ubuntu Precise 12.04 (LTS) (64-bit)下面安装docker\n\n简介：本篇文章介绍如何在ubunu 12.04版本下面安装docker\n内核要求：\n安装Docker：\n内核要求：\n由于LXC的一个bug，Docker在3.8内核下面运行最佳。Ubuntu的Precise版本内置的是3.2版本的内核，因此我们首先需要升级内核。安装下面的步骤可以升级到3.8内核，并内置AUFS的支持。同时还包括了通用头文件，这样我们就可以激活依赖于这些头文件的包，比如ZFS，VirtualBox的增强功能包。\n\n```\n# install the backported kernel\nsudo apt-get update\nsudo apt-get install linux-image-generic-lts-raring linux-headers-generic-lts-raring\n# reboot\nsudo reboot\n```\n\n安装Docker：\nDocker有deb格式的安装包，安装起来非常的容易。首先添加Docker库的密钥。\n\n```\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9\n```\n\n然后把Docker的库添加到apt的源列表中，更新并安装lxc-docker包。\n\n```\nsudo sh -c \"echo deb http://get.docker.io/ubuntu docker main\\\n> /etc/apt/sources.list.d/docker.list\"\nsudo apt-get update\nsudo apt-get install lxc-docker\n```\n\n安装过程中会有一个警告信息，输入\"yes\"继续安装即可。安装成功之后，可以下载ubuntu镜像并启动一个镜像来验证安装是否正常。\n\n```\nsudo docker run -i -t ubuntu /bin/bash\n```\n\n成功运行之后，输入exit退出即可。\n\n基于上面的文章，请回答如何添加Docker库的密钥？",
        "lang": "CN",
        "output": "添加Docker库的密钥的步骤如下：\n\n```bash\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 36A1D7869245C8950F966E92D8576A8BA88D21E9\n```\n\n这条命令会从Ubuntu的密钥服务器上下载并添加Docker库的公钥，这样在安装Docker时，APT软件包工具就能验证下载的软件包是否是原始的，未被篡改过的。",
        "question_num": 36,
        "source": "human",
        "type": "mrc_software"
    },
    {
        "instruction": "Pandas 是 Python 的核心数据分析支持库，提供了快速、灵活、明确的数据结构，旨在简单、直观地处理关系型、标记型数据。Pandas 的目标是成为 Python 数据分析实践与实战的必备高级工具，其长远目标是成为最强大、最灵活、可以支持任何语言的开源数据分析工具。经过多年不懈的努力，Pandas 离这个目标已经越来越近了。\n\nPandas 适用于处理以下类型的数据：\n\n与 SQL 或 Excel 表类似的，含异构列的表格数据;\n有序和无序（非固定频率）的时间序列数据;\n带行列标签的矩阵数据，包括同构或异构型数据;\n任意其它形式的观测、统计数据集, 数据转入 Pandas 数据结构时不必事先标记。\nPandas 的主要数据结构是 Series（一维数据）与 DataFrame（二维数据），这两种数据结构足以处理金融、统计、社会科学、工程等领域里的大多数典型用例。对于 R 用户，DataFrame 提供了比 R 语言 data.frame 更丰富的功能。Pandas 基于 NumPy 开发，可以与其它第三方科学计算支持库完美集成。\n\nPandas 就像一把万能瑞士军刀，下面仅列出了它的部分优势 ：\n\n处理浮点与非浮点数据里的缺失数据，表示为 NaN；\n大小可变：插入或删除 DataFrame 等多维对象的列；\n自动、显式数据对齐：显式地将对象与一组标签对齐，也可以忽略标签，在 Series、DataFrame 计算时自动与数据对齐；\n强大、灵活的分组（group by）功能：拆分-应用-组合数据集，聚合、转换数据；\n把 Python 和 NumPy 数据结构里不规则、不同索引的数据轻松地转换为 DataFrame 对象；\n基于智能标签，对大型数据集进行切片、花式索引、子集分解等操作；\n直观地合并（merge）、**连接（join）**数据集；\n灵活地重塑（reshape）、**透视（pivot）**数据集；\n轴支持结构化标签：一个刻度支持多个标签；\n成熟的 IO 工具：读取文本文件（CSV 等支持分隔符的文件）、Excel 文件、数据库等来源的数据，利用超快的 HDF5 格式保存 / 加载数据；\n时间序列：支持日期范围生成、频率转换、移动窗口统计、移动窗口线性回归、日期位移等时间序列功能。\n这些功能主要是为了解决其它编程语言、科研环境的痛点。处理数据一般分为几个阶段：数据整理与清洗、数据分析与建模、数据可视化与制表，Pandas 是处理数据的理想工具。\n\n其它说明：\n\nPandas 速度很快。Pandas 的很多底层算法都用 Cython 优化过。然而，为了保持通用性，必然要牺牲一些性能，如果专注某一功能，完全可以开发出比 Pandas 更快的专用工具。\nPandas 是 statsmodels 的依赖项，因此，Pandas 也是 Python 中统计计算生态系统的重要组成部分。\nPandas 已广泛应用于金融领域。\n\n基于上面的文章请回答pandas有哪些优势？",
        "lang": "CN",
        "output": "Pandas 有以下优势：\n1. 处理浮点与非浮点数据里的缺失数据，表示为 NaN；\n2. 大小可变：插入或删除 DataFrame 等多维对象的列；\n3. 自动、显式数据对齐：显式地将对象与一组标签对齐，也可以忽略标签，在 Series、DataFrame 计算时自动与数据对齐；\n4. 强大、灵活的分组（group by）功能：拆分-应用-组合数据集，聚合、转换数据；\n5. 把 Python 和 NumPy 数据结构里不规则、不同索引的数据轻松地转换为 DataFrame 对象；\n6. 基于智能标签，对大型数据集进行切片、花式索引、子集分解等操作；\n7. 直观地合并（merge）、连接（join）数据集；\n8. 灵活地重塑（reshape）、透视（pivot）数据集；\n9. 轴支持结构化标签：一个刻度支持多个标签；\n10. 成熟的 IO 工具：读取文本文件（CSV 等支持分隔符的文件）、Excel 文件、数据库等来源的数据，利用超快的 HDF5 格式保存 / 加载数据；\n11. 时间序列：支持日期范围生成、频率转换、移动窗口统计、移动窗口线性回归、日期位移等时间序列功能。\n这些功能主要是为了解决其它编程语言、科研环境的痛点。处理数据一般分为几个阶段：数据整理与清洗、数据分析与建模、数据可视化与制表，Pandas 是处理数据的理想工具。",
        "question_num": 33,
        "source": "human",
        "type": "mrc_software"
    }
]